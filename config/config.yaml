common:
  seed: 1337
data:
  root: "data"
  sample_rate: 8192
  train_size: 0.95
preprocessing:
  win_length: 1023
  hop_length: 768
  n_fft: 1023
  clip_min_value: 1e-5
  crop_size: 98303  # 768 * 128 - 1
  val_crop_size: 983039
model:  # See WaveNet class in src/core/model.py for descriptions
  checkpoint_path: ???  #"./last.ckpt"  # Path to lightning checkpoint to continue training (ignores further parameters)
  conv_channels_list: [16, 32, 64, 128, 256, 512]
  kernel_size: 5
optimizer:
  lr: 1e-3
training:
  gpus: 1  # Number of gpus (not list of indices)
  n_epochs: 1000
  num_workers: 12
  batch_size: 64
  val_check_interval: 1.0
  epoch_size: 32000
  transform_on_cuda: True
wandb:
  project: "Tamerlan-Tabolov-AudioSeparation"
  log_freq: 3
train_transforms:
  - _target_: core.transforms.ToMono
  - _target_: core.transforms.Squeeze
  - _target_: core.transforms.ToNumpy
  - _target_: audiomentations.TimeStretch
    min_rate: 0.7
    max_rate: 1.3
    p: 0.5
  - _target_: audiomentations.PitchShift
    min_semitones: -4
    max_semitones: 4
    p: 0.5
  - _target_: core.transforms.ToTorch
inference_transforms:
  - _target_: core.transforms.ToMono
  - _target_: core.transforms.Squeeze
inference:
  device: "cuda"
  checkpoint_path: "./last.ckpt"
  spectrogram_path: ???  # Path to input spectrogram with .pt extension. Can be produced with audio_to_spec.py or torch.save
  inferenced_path: "inferenced"  # Path to dir with inferenced files
  cut_size: null # size of cut in seconds
audio_to_spec:
  audio_path: ???
  output_path: "inferenced"
